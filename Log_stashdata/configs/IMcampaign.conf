#D:\CoreDeveloper\logstash\bin>logstash -f  D:\CoreDeveloper\imdata\MXIMproducts.conf


input {
  jdbc {
     jdbc_driver_library => "${DATABASE_DRIVER_PATH}\sqljdbc42.jar"
     jdbc_driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
     jdbc_connection_string => "jdbc:sqlserver://${DATABASE_HOST}:${DATABASE_PORT};databasename=${DATABASE}"
     jdbc_user => "${DATABASE_USERNAME}"
     jdbc_password => "${DATABASE_PASSWORD}"
     statement_filepath => "${LOGSTASH_SQL_FILEPATH}\campaign.sql"
  }
}

filter {	
  aggregate {
    task_id => "%{x_rec_spec}"
    code => "
      map['x_rec_spec'] = event.get('x_rec_spec')      
	  map['campaign'] ||= []
	  map['campaign'] << {'promotiontype' => event.get('promotiontype'),'promotioncode' => event.get('promotioncode'),'promotionpoints' => event.get('promotionpoints')}
    "
    push_previous_map_as_event => true
    timeout => 50000
    timeout_tags => ['aggregated']
  }
  if "aggregated" not in [tags] {
    drop {}
  }
}
  
output {
    elasticsearch {
        action => "update"        
		hosts => ["${ELASTICSEARCH_HOST}"]
		user => "${ELASTICSEARCH_USER}"
        password => "${ELASTICSEARCH_PASSWORD}"        
		index => "${IMPRODUCT_INDEX_NAME}"
        doc_as_upsert => true
        document_type => "product"
        document_id => "%{x_rec_spec}"
        flush_size => 500
    }
    #stdout { codec => rubydebug }
	stdout { codec => dots }
}
