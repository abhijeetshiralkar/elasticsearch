
input {
  jdbc {
     jdbc_driver_library => "${DATABASE_DRIVER_PATH}\sqljdbc42.jar"
     jdbc_driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
     jdbc_connection_string => "jdbc:sqlserver://${DATABASE_HOST}:${DATABASE_PORT};databasename=${DATABASE}"
     jdbc_user => "${DATABASE_USERNAME}"
     jdbc_password => "${DATABASE_PASSWORD}"
     statement_filepath => "${LOGSTASH_SQL_FILEPATH}\price.sql"
  }
}

filter {
	mutate {
     split => { "customerkey" => ","}
	 }
  aggregate {
    task_id => "%{x_rec_spec}"
    code => "
      map['x_rec_spec'] = event.get('x_rec_spec')      
	  map['prices'] ||= []
	  map['prices'] << {'customerkey' => event.get('customerkey'),'promotionflag' => event.get('promotionflag'),'webdiscountflag' => event.get('webdiscountflag'),'quantitybreakflag' => event.get('quantitybreakflag'),'shipalongflagdim' => event.get('shipalongflagdim'),'promoenddt' => event.get('promoenddt'),'shipalongmaterial' => event.get('shipalongmaterial'),'shipalongminqty' => event.get('shipalongminqty'),'shipalongfreeqty' => event.get('shipalongfreeqty'),'shipalongexpiredt' => event.get('shipalongexpiredt'),'shipalongpartdes' => event.get('shipalongpartdes')}
    "
    push_previous_map_as_event => true
    timeout => 50000
    timeout_tags => ['aggregated']
  }
  if "aggregated" not in [tags] {
    drop {}
  }
}
  
output {
    elasticsearch {
        action => "update"
		hosts => ["${ELASTICSEARCH_HOST}"]
		user => "${ELASTICSEARCH_USER}"
        password => "${ELASTICSEARCH_PASSWORD}"
		index => "${IMPRODUCT_INDEX_NAME}"
        doc_as_upsert => true
        document_type => "product"
        document_id => "%{x_rec_spec}"
        flush_size => 500
    }
    #stdout { codec => rubydebug }
	stdout { codec => dots }
}
