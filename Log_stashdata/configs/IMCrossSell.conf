#D:\CoreDeveloper\logstash\bin>logstash -f  D:\CoreDeveloper\imdata\MXIMproducts.conf


input {
  jdbc {
     jdbc_driver_library => "${DATABASE_DRIVER_PATH}\sqljdbc42.jar"
     jdbc_driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
     jdbc_connection_string => "jdbc:sqlserver://${DATABASE_HOST}:${DATABASE_PORT};databasename=${DATABASE}"
     jdbc_user => "${DATABASE_USERNAME}"
     jdbc_password => "${DATABASE_PASSWORD}"
     statement_filepath => "${LOGSTASH_SQL_FILEPATH}\crosssell.sql"
  }
}

filter {
aggregate {
    task_id => "%{x_rec_spec}"
    code => "
	  map['x_rec_spec'] = event.get('x_rec_spec')
	  map['sku'] = event.get('sku')	
	  map['vpn'] = event.get('vpn')	
      map['cross_sell'] ||= []
      map['cross_sell'] << {'additionalmaterial' => event.get('additionalmaterial'),'contenttype' => event.get('contenttype'),'ordernumber' => event.get('ordernumber')}
    "
    push_previous_map_as_event => true
    timeout => 150000
    timeout_tags => ['aggregated']
  }
  if "aggregated" not in [tags] {
    drop {}
  }
}
  
output {
    elasticsearch {
        action => "update"
		hosts => ["${ELASTICSEARCH_HOST}"]
		user => "${ELASTICSEARCH_USER}"
        password => "${ELASTICSEARCH_PASSWORD}"
		index => "${IMPRODUCT_DETAIL_INDEX_NAME}"
        doc_as_upsert => true
        document_type => "product"
        document_id => "%{x_rec_spec}"
        flush_size => 500
		retry_on_conflict => 50
    }
    #stdout { codec => rubydebug }
	stdout { codec => dots }
}
